# Sistema RAG - AnÃ¡lisis de Ventas

Sistema de anÃ¡lisis de datos de ventas utilizando **RAG (Retrieval-Augmented Generation)** con embeddings, vectorstore FAISS y LLM local (Ollama).

## ğŸ“ Estructura del Proyecto

```
src/tarea_rag/
â”œâ”€â”€ config.py              # ConfiguraciÃ³n del sistema (rutas, modelos, constantes)
â”œâ”€â”€ data_loader.py         # Carga de datos CSV y creaciÃ³n de documentos
â”œâ”€â”€ vectorstore.py         # GestiÃ³n del vectorstore FAISS con embeddings
â”œâ”€â”€ query_processor.py     # Procesamiento de consultas usando RAG
â”œâ”€â”€ rag_api.py             # API Flask (endpoints y rutas)
â”œâ”€â”€ data/                  # Archivos CSV de datos
â”‚   â”œâ”€â”€ Clientes-Tabla 1.csv
â”‚   â”œâ”€â”€ Productos-Tabla 1.csv
â”‚   â””â”€â”€ Ventas-Tabla 1.csv
â””â”€â”€ static/                # Frontend (HTML, CSS, JS)
    â”œâ”€â”€ index.html
    â”œâ”€â”€ styles.css
    â””â”€â”€ script.js
```

## ğŸ—ï¸ Arquitectura RAG

### Flujo del Sistema

1. **Carga de Datos** (`data_loader.py`)
   - Lee archivos CSV de clientes, productos y ventas
   - Enriquece datos con JOINs
   - Crea documentos estructurados con metadata

2. **VectorizaciÃ³n** (`vectorstore.py`)
   - Genera embeddings usando HuggingFace Transformers
   - Almacena en vectorstore FAISS
   - Indexa para bÃºsqueda por similaridad

3. **Consulta RAG** (`query_processor.py`)
   - BÃºsqueda semÃ¡ntica de documentos relevantes
   - ConstrucciÃ³n de contexto
   - GeneraciÃ³n de respuesta con LLM

4. **API REST** (`rag_api.py`)
   - Endpoints Flask
   - IntegraciÃ³n con frontend

### MÃ³dulos Principales

#### 1. **config.py**
- ConfiguraciÃ³n centralizada
- ParÃ¡metros del modelo LLM (Ollama)
- ConfiguraciÃ³n de embeddings (HuggingFace)
- Constantes RAG (top_k, temperature)

#### 2. **data_loader.py**
- Clase `DataLoader`: Carga y procesa datos
- MÃ©todo `create_documents()`: Convierte datos en documentos LangChain
- Crea documentos para:
  - Ventas individuales con detalles completos
  - ResÃºmenes por cliente
  - ResÃºmenes por producto
  - ResÃºmenes por categorÃ­a

#### 3. **vectorstore.py**
- Clase `VectorStoreManager`: Gestiona FAISS
- Inicializa modelo de embeddings multilingÃ¼e
- MÃ©todos:
  - `create_vectorstore()`: Crea Ã­ndice vectorial
  - `similarity_search()`: BÃºsqueda semÃ¡ntica
  - `similarity_search_with_score()`: Con scores de similaridad

#### 4. **query_processor.py**
- Clase `QueryProcessor`: Procesa consultas con RAG
- Usa `RetrievalQA` de LangChain
- Pipeline:
  1. Usuario hace pregunta
  2. BÃºsqueda vectorial de documentos relevantes (top_k)
  3. ConstrucciÃ³n de contexto
  4. GeneraciÃ³n de respuesta con LLM
  5. Respuesta en lenguaje natural

#### 5. **rag_api.py**
- API Flask con endpoints REST
- Endpoints:
  - `GET /`: PÃ¡gina principal
  - `GET /<filename>`: Archivos estÃ¡ticos
  - `GET /api/health`: Estado del servicio
  - `GET /api/stats`: EstadÃ­sticas generales
  - `POST /api/query`: Procesar consultas RAG

#### 6. **Frontend (static/)**
- **index.html**: Estructura de la interfaz
- **styles.css**: Estilos y diseÃ±o visual
- **script.js**: LÃ³gica del cliente

## ğŸš€ EjecuciÃ³n

```bash
cd tarea_rag/tarea_rag
poetry run python src/tarea_rag/rag_api.py
```

El servidor estarÃ¡ disponible en: `http://localhost:5001`

## ğŸ¯ Flujo de Trabajo RAG

1. **Usuario hace pregunta** â†’ Frontend envÃ­a POST a `/api/query`
2. **BÃºsqueda vectorial** â†’ Sistema busca los 5 documentos mÃ¡s relevantes por similaridad semÃ¡ntica
3. **ConstrucciÃ³n de contexto** â†’ Documentos recuperados se usan como contexto
4. **GeneraciÃ³n LLM** â†’ El LLM genera respuesta basÃ¡ndose en el contexto
5. **Respuesta al usuario** â†’ Frontend muestra respuesta + fuentes utilizadas

## ğŸ“Š Datos

El sistema convierte datos CSV en documentos vectorizados:
- **Clientes**: InformaciÃ³n y resÃºmenes de compras
- **Productos**: CatÃ¡logo con estadÃ­sticas de ventas
- **Ventas**: Transacciones individuales con detalles completos
- **Agregaciones**: ResÃºmenes por cliente, producto y categorÃ­a

## ğŸ› ï¸ TecnologÃ­as

### Backend
- **Flask**: API REST
- **Pandas**: Procesamiento de datos
- **LangChain**: Framework RAG
- **FAISS**: Vectorstore para bÃºsqueda por similaridad
- **HuggingFace Transformers**: GeneraciÃ³n de embeddings
- **Ollama**: LLM local (DeepSeek v3.1)

### Frontend
- **HTML5, CSS3, JavaScript**: Interfaz de usuario

### Modelos
- **LLM**: DeepSeek v3.1 (vÃ­a Ollama)
- **Embeddings**: paraphrase-multilingual-MiniLM-L12-v2

## ğŸ“ Ventajas del Sistema RAG

âœ… **No genera cÃ³digo**: Respuestas directas basadas en informaciÃ³n recuperada
âœ… **BÃºsqueda semÃ¡ntica**: Encuentra informaciÃ³n relevante aunque use palabras diferentes
âœ… **Contexto preciso**: Solo usa informaciÃ³n relevante de la base de datos
âœ… **Escalable**: FÃ¡cil agregar mÃ¡s datos sin cambiar cÃ³digo
âœ… **Transparente**: Muestra las fuentes usadas para cada respuesta
âœ… **MultilingÃ¼e**: Embeddings optimizados para espaÃ±ol
